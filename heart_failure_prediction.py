# -*- coding: utf-8 -*-
"""heart failure prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fbloLwJWoERajfJt3PhCqoZRS5wOTGpm
"""

pip list

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn import svm
from tensorflow.keras.layers import Dense,BatchNormalization,Dropout,LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras import callbacks

from sklearn.metrics import precision_score,recall_score,confusion_matrix,accuracy_score,f1_score,classification_report

data_df=pd.read_csv('/content/heart_failure_clinical_records_dataset.csv')

data_df

data_df.info()

cols = ["#00FF00","#FF0000"]
ax=sns.countplot(x=data_df["DEATH_EVENT"],palette=cols)
ax.bar_label(ax.containers[0])

data_df.describe()

sns.heatmap(data_df.corr(),annot=True)

plt.subplots(figsize=(15,10))
sns.heatmap(data_df.corr(),cmap="BuGn",annot=True)
plt.show()

plt.figure(figsize=(15,10))
days_of_week=sns.countplot(x=data_df['age'],data=data_df,hue="DEATH_EVENT",palette=cols)

feature = ["age", "creatinine_phosphokinase","ejection_fraction","platelets","serum_creatinine","serum_sodium","time"]
for i in feature:
  plt.figure(figsize=(10,5))

  sns.swarmplot(y=data_df[i],x=data_df["DEATH_EVENT"],data=data_df,color="black",alpha=0.7)
  sns.boxenplot(y=data_df[i],x=data_df["DEATH_EVENT"],data=data_df,color="black",alpha=0.7)

x=data_df.drop("DEATH_EVENT",axis=1)
y=data_df["DEATH_EVENT"]

col_name = list(x.columns)
s_scalar=preprocessing.StandardScaler()
x_scaled=s_scalar.fit_transform(x)
x_scaled=pd.DataFrame(x_scaled,columns=col_name)

x_scaled.describe().T

plt.figure(figsize=(20,15))
sns.boxenplot(data=x_scaled)
plt.show()

x_train,x_tests,y_train,y_tests=train_test_split(x_scaled,y,test_size=0.3)

model1=svm.SVC()

model1.fit(x_train,y_train)

model1.predict(x_tests)

y_pred=model1.predict(x_tests)

y_pred

y_tests

y_train

print(classification_report(y_tests,y_pred))

from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping

early_stopping=EarlyStopping(min_delta=0.001,patience=20,restore_best_weights=True)
model=Sequential()
model.add(Dense(units=16,kernel_initializer="uniform",activation="relu",input_dim=12)) # Use Dense
model.add(Dense(units=8,kernel_initializer="uniform",activation="relu"))
model.add(Dropout(0.25))
model.add(Dense(units=8,kernel_initializer="uniform",activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(units=1,kernel_initializer="uniform",activation="sigmoid"))

model.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

model.summary()

history=model.fit(x_train,y_train,batch_size=25,epochs=100,callbacks=[early_stopping],validation_split=0.25)

history_df=pd.DataFrame(history.history)
plt.plot(history_df.loc[:,['loss']],label="Training Loss")
plt.plot(history_df.loc[:,['val_loss']],label="Validation Loss")
plt.legend()
plt.show()

plt.plot(history_df.loc[:,['accuracy']],label="Training accuracy")
plt.plot(history_df.loc[:,['val_accuracy']],label="Validation accuracy")
plt.legend()
plt.show()

y_pred=model.predict(x_tests)

y_pred = (y_pred > 0.5)

print(classification_report(y_tests,y_pred))